{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45c3399c-b280-4712-915c-4991e5be8367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\night\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\night\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: gensim in c:\\users\\night\\anaconda3\\lib\\site-packages (4.3.3)\n",
      "Collecting pyLDAvis\n",
      "  Downloading pyLDAvis-3.4.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\night\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\night\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\night\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\night\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: click in c:\\users\\night\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\night\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\night\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\night\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\night\\anaconda3\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\night\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\night\\anaconda3\\lib\\site-packages (from pyLDAvis) (3.1.4)\n",
      "Requirement already satisfied: numexpr in c:\\users\\night\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.8.7)\n",
      "Collecting funcy (from pyLDAvis)\n",
      "  Downloading funcy-2.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\night\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.5.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\night\\anaconda3\\lib\\site-packages (from pyLDAvis) (75.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\night\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\night\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\night\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\night\\anaconda3\\lib\\site-packages (from jinja2->pyLDAvis) (2.1.3)\n",
      "Downloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 1.3/2.6 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 7.9 MB/s eta 0:00:00\n",
      "Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
      "Installing collected packages: funcy, pyLDAvis\n",
      "Successfully installed funcy-2.0 pyLDAvis-3.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas nltk gensim pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9deb8e6d-2df0-4674-864d-f8ae48cecace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import pyLDAvis.gensim_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cdac945-edae-4f00-bd6e-82d9602f1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\night\\Downloads\\news_dataset.csv\")\n",
    "texts = df['text'].dropna().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2c59887-870e-4f0a-bbf2-f6dc33bc4830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\night\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\night\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a8e200c-395b-48ef-9c6e-f3fee89000cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9153fea1-9cca-44a3-a12a-5b2f7d51f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text.lower())  # Tokenize and lowercase\n",
    "    tokens = [ps.stem(word) for word in tokens if word.isalpha() and word not in stop_words]  # Remove stopwords and apply stemming\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae643ec7-8afd-42ce-b070-00671290b458",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_texts = [preprocess(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54bdf15e-6d71-45f0-81d3-b74ea0d3864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(processed_texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in processed_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "648515f2-1f7d-4a5e-8d28-04aef122f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaModel(corpus, num_topics=4, id2word=dictionary, passes=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5f8eda2-3e77-466b-a7b7-5ddf609ed7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model = CoherenceModel(model=lda_model, texts=processed_texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence_score = coherence_model.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4d98c29-a8a9-40c5-9c19-054a01b60f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = lda_model.print_topics(num_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "201fcd3a-7187-4113-b182-307068914c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score: 0.6168683749401351\n",
      "\n",
      "Topics:\n",
      "(0, '0.016*\"use\" + 0.010*\"key\" + 0.007*\"file\" + 0.007*\"system\" + 0.007*\"encrypt\"')\n",
      "(1, '0.005*\"year\" + 0.005*\"armenian\" + 0.005*\"game\" + 0.005*\"team\" + 0.004*\"state\"')\n",
      "(2, '0.063*\"x\" + 0.059*\"q\" + 0.053*\"max\" + 0.034*\"g\" + 0.033*\"r\"')\n",
      "(3, '0.011*\"would\" + 0.009*\"one\" + 0.009*\"peopl\" + 0.007*\"think\" + 0.006*\"like\"')\n"
     ]
    }
   ],
   "source": [
    "print(f\"Coherence Score: {coherence_score}\")\n",
    "print(\"\\nTopics:\")\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb223e10-9c0c-4593-b1f1-c7f865cb1380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "3      0.178340  0.013921       1        1  45.820775\n",
       "0      0.121021  0.181499       2        1  27.951748\n",
       "1      0.098085 -0.206076       3        1  19.940552\n",
       "2     -0.397446  0.010656       4        1   6.286924, topic_info=        Term         Freq        Total Category  logprob  loglift\n",
       "1586       x  5396.000000  5396.000000  Default  30.0000  30.0000\n",
       "3247       q  3975.000000  3975.000000  Default  29.0000  29.0000\n",
       "2971     max  3522.000000  3522.000000  Default  28.0000  28.0000\n",
       "1051       g  2250.000000  2250.000000  Default  27.0000  27.0000\n",
       "4047       r  2233.000000  2233.000000  Default  26.0000  26.0000\n",
       "...      ...          ...          ...      ...      ...      ...\n",
       "2112       b   985.555926  1161.903034   Topic4  -4.2181   2.6021\n",
       "2501       c   974.298169  1321.513240   Topic4  -4.2296   2.4619\n",
       "7385  printf   133.115833   145.466407   Topic4  -6.2201   2.6780\n",
       "2308      ah   195.730993   253.000583   Topic4  -5.8346   2.5100\n",
       "2000   entri   213.991073   508.066080   Topic4  -5.7454   1.9020\n",
       "\n",
       "[290 rows x 6 columns], token_table=      Topic      Freq       Term\n",
       "term                            \n",
       "743       1  0.955272       agre\n",
       "743       3  0.044065       agre\n",
       "2308      1  0.225296         ah\n",
       "2308      4  0.774702         ah\n",
       "7262      2  0.998652  algorithm\n",
       "...     ...       ...        ...\n",
       "35        2  0.075667       year\n",
       "35        3  0.449246       year\n",
       "1871      2  0.027351       york\n",
       "1871      3  0.970949       york\n",
       "1587      4  0.999697          z\n",
       "\n",
       "[468 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 1, 2, 3])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e1c33e-96f6-4e8a-a2ba-a3457cc40c38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
