{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bf43fa6-5629-4116-be89-b15fb29c1771",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\night\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\night\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\night\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dbadd37-1200-4945-8a52-41e88bbba5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89c850dc-358c-4490-bff3-73a3706acaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Remove stopwords and lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1344b4ff-413b-4e8d-8d7e-f98ff3e06ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    \"I love playing football on the weekends\",\n",
    "    \"I enjoy hiking and camping in the mountains\",\n",
    "    \"I like to read books and watch movies\",\n",
    "    \"I prefer playing video games over sports\",\n",
    "    \"I love listening to music and going to concerts\"\n",
    "]\n",
    "\n",
    "preprocessed_dataset = [preprocess_text(doc) for doc in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "826e19b1-736e-44b0-9199-1f883b5903a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3â€“5: Same as original but using preprocessed data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from tabulate import tabulate\n",
    "from collections import Counter\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(preprocessed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab5dfb44-4a60-4e78-bac9-0710a5182f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "km = KMeans(n_clusters=k)\n",
    "km.fit(X)\n",
    "y_pred = km.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "533edfd8-7c6c-41fe-a4de-8e1267d4848d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document                                           Predicted Cluster\n",
      "-----------------------------------------------  -------------------\n",
      "I love playing football on the weekends                            0\n",
      "I enjoy hiking and camping in the mountains                        1\n",
      "I like to read books and watch movies                              0\n",
      "I prefer playing video games over sports                           0\n",
      "I love listening to music and going to concerts                    0\n"
     ]
    }
   ],
   "source": [
    "table_data = [[\"Document\", \"Predicted Cluster\"]]\n",
    "table_data.extend([[doc, cluster] for doc, cluster in zip(dataset, y_pred)])\n",
    "print(tabulate(table_data, headers=\"firstrow\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9a6fa29-0c47-42ef-83ee-1ad8e1285e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " love\n",
      " playing\n",
      " football\n",
      " weekend\n",
      " going\n",
      " sport\n",
      " music\n",
      " concert\n",
      " video\n",
      " game\n",
      "\n",
      "Cluster 1:\n",
      " camping\n",
      " enjoy\n",
      " hiking\n",
      " mountain\n",
      " weekend\n",
      " listening\n",
      " concert\n",
      " football\n",
      " game\n",
      " going\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTop terms per cluster:\")\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "for i in range(k):\n",
    "    print(f\"Cluster {i}:\")\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(f\" {terms[ind]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b63f125e-f74f-4a30-956b-bf72f3bdaa25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity: 0.8\n"
     ]
    }
   ],
   "source": [
    "cluster_label_counts = [Counter(y_pred)]\n",
    "purity = sum(max(cluster.values()) for cluster in cluster_label_counts) / len(y_pred)\n",
    "print(\"Purity:\", purity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f967c15-5413-42a3-a2d9-8c73cd0b73a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
